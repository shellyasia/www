<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7966848a1f870e4c42edb4db67b13c57",
  "translation_date": "2025-08-25T00:15:39+00:00",
  "source_file": "6-consumer/lessons/3-spoken-feedback/virtual-device-text-to-speech.md",
  "language_code": "zh"
}
-->
# æ–‡æœ¬è½¬è¯­éŸ³ - è™šæ‹Ÿç‰©è”ç½‘è®¾å¤‡

åœ¨æœ¬èŠ‚è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†ç¼–å†™ä»£ç ï¼Œé€šè¿‡è¯­éŸ³æœåŠ¡å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³ã€‚

## å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³

æ‚¨åœ¨ä¸Šä¸€èŠ‚è¯¾ä¸­ä½¿ç”¨çš„è¯­éŸ³æœåŠ¡ SDK å¯ä»¥å°†è¯­éŸ³è½¬æ¢ä¸ºæ–‡æœ¬ï¼ŒåŒæ ·ä¹Ÿå¯ä»¥å°†æ–‡æœ¬è½¬æ¢å›è¯­éŸ³ã€‚åœ¨è¯·æ±‚è¯­éŸ³æ—¶ï¼Œæ‚¨éœ€è¦æä¾›ä½¿ç”¨çš„è¯­éŸ³ï¼Œå› ä¸ºè¯­éŸ³å¯ä»¥é€šè¿‡å¤šç§ä¸åŒçš„å£°éŸ³ç”Ÿæˆã€‚

æ¯ç§è¯­è¨€éƒ½æ”¯æŒä¸€ç³»åˆ—ä¸åŒçš„å£°éŸ³ï¼Œæ‚¨å¯ä»¥é€šè¿‡è¯­éŸ³æœåŠ¡ SDK è·å–æ¯ç§è¯­è¨€æ”¯æŒçš„å£°éŸ³åˆ—è¡¨ã€‚

### ä»»åŠ¡ - å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³

1. åœ¨ VS Code ä¸­æ‰“å¼€ `smart-timer` é¡¹ç›®ï¼Œå¹¶ç¡®ä¿è™šæ‹Ÿç¯å¢ƒå·²åœ¨ç»ˆç«¯ä¸­åŠ è½½ã€‚

1. ä» `azure.cognitiveservices.speech` åŒ…ä¸­å¯¼å…¥ `SpeechSynthesizer`ï¼Œå°†å…¶æ·»åŠ åˆ°ç°æœ‰çš„å¯¼å…¥ä¸­ï¼š

    ```python
    from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, SpeechSynthesizer
    ```

1. åœ¨ `say` å‡½æ•°ä¸Šæ–¹ï¼Œåˆ›å»ºä¸€ä¸ªè¯­éŸ³é…ç½®ä»¥ä¾›è¯­éŸ³åˆæˆå™¨ä½¿ç”¨ï¼š

    ```python
    speech_config = SpeechConfig(subscription=speech_api_key,
                                 region=location)
    speech_config.speech_synthesis_language = language
    speech_synthesizer = SpeechSynthesizer(speech_config=speech_config)
    ```

    è¿™ä½¿ç”¨äº†ä¸è¯†åˆ«å™¨ç›¸åŒçš„ API å¯†é’¥ã€ä½ç½®å’Œè¯­è¨€ã€‚

1. åœ¨å…¶ä¸‹æ–¹æ·»åŠ ä»¥ä¸‹ä»£ç ä»¥è·å–è¯­éŸ³å¹¶å°†å…¶è®¾ç½®åˆ°è¯­éŸ³é…ç½®ä¸­ï¼š

    ```python
    voices = speech_synthesizer.get_voices_async().get().voices
    first_voice = next(x for x in voices if x.locale.lower() == language.lower())
    speech_config.speech_synthesis_voice_name = first_voice.short_name
    ```

    è¿™ä¼šæ£€ç´¢æ‰€æœ‰å¯ç”¨è¯­éŸ³çš„åˆ—è¡¨ï¼Œç„¶åæ‰¾åˆ°ä¸æ­£åœ¨ä½¿ç”¨çš„è¯­è¨€åŒ¹é…çš„ç¬¬ä¸€ä¸ªè¯­éŸ³ã€‚

    > ğŸ’ æ‚¨å¯ä»¥ä» [Microsoft Docs ä¸Šçš„è¯­è¨€å’Œè¯­éŸ³æ”¯æŒæ–‡æ¡£](https://docs.microsoft.com/azure/cognitive-services/speech-service/language-support?WT.mc_id=academic-17441-jabenn#text-to-speech) è·å–æ”¯æŒçš„è¯­éŸ³çš„å®Œæ•´åˆ—è¡¨ã€‚å¦‚æœæ‚¨æƒ³ä½¿ç”¨ç‰¹å®šçš„è¯­éŸ³ï¼Œå¯ä»¥ç§»é™¤æ­¤å‡½æ•°å¹¶å°†è¯­éŸ³åç§°ç¡¬ç¼–ç ä¸ºæ–‡æ¡£ä¸­çš„è¯­éŸ³åç§°ã€‚ä¾‹å¦‚ï¼š
    >
    > ```python
    > speech_config.speech_synthesis_voice_name = 'hi-IN-SwaraNeural'
    > ```

1. æ›´æ–° `say` å‡½æ•°çš„å†…å®¹ä»¥ç”Ÿæˆå“åº”çš„ SSMLï¼š

    ```python
    ssml =  f'<speak version=\'1.0\' xml:lang=\'{language}\'>'
    ssml += f'<voice xml:lang=\'{language}\' name=\'{first_voice.short_name}\'>'
    ssml += text
    ssml += '</voice>'
    ssml += '</speak>'
    ```

1. åœ¨å…¶ä¸‹æ–¹ï¼Œåœæ­¢è¯­éŸ³è¯†åˆ«ï¼Œæ’­æ”¾ SSMLï¼Œç„¶åé‡æ–°å¯åŠ¨è¯†åˆ«ï¼š

    ```python
    recognizer.stop_continuous_recognition()
    speech_synthesizer.speak_ssml(ssml)
    recognizer.start_continuous_recognition()
    ```

    åœ¨æ’­æ”¾æ–‡æœ¬æ—¶åœæ­¢è¯†åˆ«ï¼Œä»¥é¿å…è®¡æ—¶å™¨å¯åŠ¨çš„è¯­éŸ³è¢«æ£€æµ‹åˆ°å¹¶å‘é€åˆ° LUISï¼Œå¯èƒ½ä¼šè¢«è§£é‡Šä¸ºè®¾ç½®æ–°è®¡æ—¶å™¨çš„è¯·æ±‚ã€‚

    > ğŸ’ æ‚¨å¯ä»¥é€šè¿‡æ³¨é‡Šæ‰åœæ­¢å’Œé‡æ–°å¯åŠ¨è¯†åˆ«çš„ä»£ç æ¥æµ‹è¯•è¿™ä¸€ç‚¹ã€‚è®¾ç½®ä¸€ä¸ªè®¡æ—¶å™¨ï¼Œæ‚¨å¯èƒ½ä¼šå‘ç°è¯­éŸ³æ’­æŠ¥ä¼šè®¾ç½®ä¸€ä¸ªæ–°è®¡æ—¶å™¨ï¼Œä»è€Œå¯¼è‡´æ–°çš„æ’­æŠ¥ï¼Œç»§è€Œè®¾ç½®æ–°çš„è®¡æ—¶å™¨ï¼Œå¦‚æ­¤å¾ªç¯å¾€å¤ï¼

1. è¿è¡Œåº”ç”¨ç¨‹åºï¼Œå¹¶ç¡®ä¿å‡½æ•°åº”ç”¨ç¨‹åºä¹Ÿåœ¨è¿è¡Œã€‚è®¾ç½®ä¸€äº›è®¡æ—¶å™¨ï¼Œæ‚¨ä¼šå¬åˆ°è¯­éŸ³å“åº”ï¼Œå‘Šè¯‰æ‚¨è®¡æ—¶å™¨å·²è®¾ç½®ï¼Œç„¶ååœ¨è®¡æ—¶å™¨å®Œæˆæ—¶ä¼šæœ‰å¦ä¸€ä¸ªè¯­éŸ³å“åº”ã€‚

> ğŸ’ æ‚¨å¯ä»¥åœ¨ [code-spoken-response/virtual-iot-device](../../../../../6-consumer/lessons/3-spoken-feedback/code-spoken-response/virtual-iot-device) æ–‡ä»¶å¤¹ä¸­æ‰¾åˆ°æ­¤ä»£ç ã€‚

ğŸ˜€ æ‚¨çš„è®¡æ—¶å™¨ç¨‹åºå¤§è·æˆåŠŸï¼
